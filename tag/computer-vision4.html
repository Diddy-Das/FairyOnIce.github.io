<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>


   <!-- Global site tag (gtag.js) - Google Analytics -->
   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-112020731-1"></script>
   <script>
   window.dataLayer = window.dataLayer || [];
   function gtag(){dataLayer.push(arguments);}
   gtag('js', new Date());

   gtag('config', 'UA-112020731-1');
   </script>

 

  <meta charset="utf-8">
  <title>Yumi's Blog - Computer Vision</title>
  <meta name="author" content="Yumi">



  <!-- https://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="https://FairyOnIce.github.io/favicon.png" rel="icon">
  <link href="https://FairyOnIce.github.io/theme/css/main.css" media="screen, projection"
rel="stylesheet" type="text/css">
 <link rel="stylesheet" href="https://FairyOnIce.github.io/theme/tipuesearch.css">
  <script src="https://FairyOnIce.github.io/theme/js/modernizr-2.0.js"></script>
  <script src="https://FairyOnIce.github.io/theme/js/ender.js"></script>
  <script src="https://FairyOnIce.github.io/theme/js/octopress.js" type="text/javascript"></script>

  <link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://FairyOnIce.github.io/">Yumi's Blog</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<form action="https://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:FairyOnIce.github.io" />
    <input class="search" type="text" name="q" results="0"
placeholder="Google Search"/>
  </fieldset>
</form>

<ul class="main-navigation">
    <li><a href="/archives.html">Archives</a></li>
      <li><a href="https://FairyOnIce.github.io/pages/deployment.html">Deployment</a></li>
      <li><a href="https://FairyOnIce.github.io/pages/quest.html">Quest</a></li>
    <li >
    <a href="https://FairyOnIce.github.io/category/blog.html">Blog</a>
    </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div class="blog-index">
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/create-jpgs-from-iphone-video.html">Extract series of JPEG files from iPhone 6S video</a>
      </h1>
      <p class="meta"><time datetime="2018-03-28T20:00:00-07:00" pubdate>Wed 28 March 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this blog, I will show how to extract image (.png) from video recorded using iphone.</p>
<h3 id="Preparation">Preparation<a class="anchor-link" href="#Preparation">¶</a></h3><p>I recorded a 10 minutes and 21 second video using my iphone 6s.
In my current directory, I have IMG7367.MOV file with:</p>
<ul>
<li>Size: 639.3 MB  </li>
<li>Dimensions: 1280 × 720</li>
</ul>
<h3 id="You-need-cv2">You need cv2<a class="anchor-link" href="#You-need-cv2">¶</a></h3><p>If you do not have cv2, please make sure to pip install it as:</p></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/create-jpgs-from-iphone-video.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Color-gray-scale-images-and-manga-using-deep-learning.html">Color gray scale images and manga using deep learning</a>
      </h1>
      <p class="meta"><time datetime="2018-03-23T21:00:00-07:00" pubdate>Fri 23 March 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this blog post, I will try to create a deep learning model that can color a gray scale image.
I follow this great blog post <a href="https://blog.floydhub.com/colorizing-b&amp;w-photos-with-neural-networks/">Colorizing B&W; Photos with Neural Networks</a>.</p>
<p>I will consider two example data to train a model:</p>
<ul>
<li>Flickr8K data </li>
<li>Hunter x Hunter anime data</li>
</ul><p>Flickr8K data is a famous public data in computer vision community, and it was also previously analyzed in my blog. The downloading process is described at <a href="https://fairyonice.github.io/Develop_an_image_captioning_deep_learning_model_using_Flickr_8K_data.html">Develop an image captioning deep learning model using Flickr 8K data</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Color-gray-scale-images-and-manga-using-deep-learning.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Color-space-defenitions-in-python-RGB-and-LAB.html">Color space definitions in python, RGB and LAB</a>
      </h1>
      <p class="meta"><time datetime="2018-03-19T21:00:00-07:00" pubdate>Mon 19 March 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this blog post, you will learn color spaces that are often used in image processing problems.
More specifically, after reading the blog, you will be familiar with using</p>
<ul>
<li><a href="http://scikit-image.org/docs/dev/api/skimage.color.html#rgb2lab">skimage.color.rgb2lab </a></li>
<li><a href="http://scikit-image.org/docs/dev/api/skimage.color.html#lab2rgb">skimage.color.lab2rgb </a></li>
<li><a href="https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py">keras.preprocessing.image.load_img</a></li>
<li><a href="https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py">keras.preprocessing.image.img_to_array</a></li>
<li><a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html">matplotlib.pyplot.imshow</a></li>
</ul><p>Let's first load two example images using keras.preprocessing.image.load_img.
The list dir_data contains the path to two jpg images.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Color-space-defenitions-in-python-RGB-and-LAB.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Download-all-images-from-Google-image-search-query-using-python.html">Download all images from Google image search query using python</a>
      </h1>
      <p class="meta"><time datetime="2018-03-15T20:00:00-07:00" pubdate>Thu 15 March 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this blog post, I describe how I download a lot of images from Google images.
I followed <a href="https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/">pyimagesearch's blog post</a> so please give credits to his blog.
His method has two steps:</p>
<ul>
<li>Step 1: The first step is to gather URL links of the images that appear in Google Images when you enter a query.
  <a href="https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/">pyimagesearch's blog post</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Download-all-images-from-Google-image-search-query-using-python.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Develop_an_image_captioning_deep_learning_model_using_Flickr_8K_data.html">Develop an image captioning deep learning model using Flickr 8K data</a>
      </h1>
      <p class="meta"><time datetime="2018-02-28T20:00:00-08:00" pubdate>Wed 28 February 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Image captioning is an interesting problem, where you can learn both computer vision techniques and natural language processing techniques. In this blog post, I will follow <a href="https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/">How to Develop a Deep Learning Photo Caption Generator from Scratch</a> and create an image caption generation model using Flicker 8K data. This model takes a single image as input and output the caption to this image.</p></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Develop_an_image_captioning_deep_learning_model_using_Flickr_8K_data.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Assess-the-robustness-of-CapsNet.html">Assess the robustness of CapsNet</a>
      </h1>
      <p class="meta"><time datetime="2018-01-29T21:00:00-08:00" pubdate>Mon 29 January 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the 
<a href="https://fairyonice.github.io/Understanding%20and%20Experimenting%20Capsule%20Networks.html">Understanding and Experimenting Capsule Networks</a>, 
I experimented <a href="https://arxiv.org/abs/1710.09829">Hinton's Capsule Network</a>.</p>
<p><a href="https://arxiv.org/abs/1710.09829">Dynamic Routing Between Capsules</a> discusses the robustness of the Capsule Networks to affine transformations:</p>
<p><em>"Experiments show that each DigitCaps capsule learns a more robust representation for each class than a traditional convolutional network. Because there is natural variance in skew, rotation, style, etc in hand written digits, the trained CapsNet is moderately robust to small affine transformations of the training data (Section 5.2, page 6)."</em></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Assess-the-robustness-of-CapsNet.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Understanding-and-Experimenting-Capsule-Networks.html">Understanding and Experimenting Capsule Networks</a>
      </h1>
      <p class="meta"><time datetime="2018-01-29T20:00:00-08:00" pubdate>Mon 29 January 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This blog is inspired by <a href="https://arxiv.org/abs/1710.09829">Dynamic Routing Between Capsules</a> and aims to understand Capsule Networks with hands-on coding.</p>
<p>I use Keras with tensorflow backend. The codes here are created by modifing <a href="https://www.kaggle.com/kmader/capsulenet-on-mnist">Kevin Mader's ipython notebook script in Kaggle competition</a>, which, in turn are written by adapting <a href="https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py">Xifeng Guo's script in Github</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Understanding-and-Experimenting-Capsule-Networks.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/CNN-modeling-with-image-translations-using-MNIST-data.html">CNN modeling with image translations using MNIST data</a>
      </h1>
      <p class="meta"><time datetime="2018-01-28T20:00:00-08:00" pubdate>Sun 28 January 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this blog, I train a standard CNN model on the MNIST data and assess its performance.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/CNN-modeling-with-image-translations-using-MNIST-data.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Learn-the-breed-of-a-dog-using-deep-learning.html">Learn the breed of a dog using deep learning</a>
      </h1>
      <p class="meta"><time datetime="2018-01-25T20:00:00-08:00" pubdate>Thu 25 January 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>My friend asked me if I can figure out the breed of his dog, Loki. 
As I am not a dog expart, I will ask opinions from deep learning. Here, I use VGG16 trained on <a href="http://www.image-net.org/">ImageNet</a> dataset.</p>
<h4 id="What-is-VGG16-and-ImageNet?">What is VGG16 and ImageNet?<a class="anchor-link" href="#What-is-VGG16-and-ImageNet?">¶</a></h4><p>According to <a href="https://en.wikipedia.org/wiki/ImageNet">Wikipedia</a>,</p>
<p><em>"The ImageNet project is a large visual database designed for use in visual object recognition software research...Since 2010, the annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) is a competition where research teams evaluate their algorithms on the given data set, and compete to achieve higher accuracy on several visual recognition tasks."</em></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Learn-the-breed-of-a-dog-using-deep-learning.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Visualization of Filters with Keras.html">Visualization of Filters with Keras</a>
      </h1>
      <p class="meta"><time datetime="2018-01-13T20:00:00-08:00" pubdate>Sat 13 January 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The goal of this blog post is to understand "what my CNN model is looking at". People call this visualization of the filters. But more precisely, what I will do here is to visualize the input images that maximizes (sum of the) activation map (or feature map) of the filters. 
I will visualize the filters of deep learning models for two different applications:</p></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Visualization of Filters with Keras.html">Read On &crarr;</a>
  </footer>
  		</article>
<div class="pagination">
    <a class="prev" href="https://FairyOnIce.github.io/tag/computer-vision5.html">&larr; Older</a>

    <a class="next" href="https://FairyOnIce.github.io/tag/computer-vision3.html">Newer &rarr;</a>
  <br />
</div></div>
<aside class="sidebar">

<section>
    <h1>Local Search</h1></hr>
    <form class="navbar-search" action="https://FairyOnIce.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="" name="q" id="tipue_search_input"><input type="submit" value="Go!"></form></li>
</section>
    
<section>

    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://FairyOnIce.github.io/multidimensional-indexling-with-tensorflow.ipynb.html">Multidimensional indexling with tensorflow</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/mahalanobis-tf2-full.html">Classification with Mahalanobis distance + full covariance using tensorflow</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/mahalanobis-tf2.html">Calculate Mahalanobis distance with tensorflow 2.0</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/Learn-the-Carlini-and-Wagners-adversarial-attack-MNIST.html">Learn the Carlini and Wagner's adversarial attack - MNIST</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/Grad-CAM-with-keras-vis.html">Grad-CAM with keras-vis</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://FairyOnIce.github.io/category/blog.html">Blog</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="https://FairyOnIce.github.io/tag/bleu.html">BLEU</a>,    <a href="https://FairyOnIce.github.io/tag/spectrogram.html">Spectrogram</a>,    <a href="https://FairyOnIce.github.io/tag/statistics.html">statistics</a>,    <a href="https://FairyOnIce.github.io/tag/nlp.html">NLP</a>,    <a href="https://FairyOnIce.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html">Object Detection using YOLOv2 on Pascal VOC2012 series</a>,    <a href="https://FairyOnIce.github.io/tag/api.html">API</a>,    <a href="https://FairyOnIce.github.io/tag/pascal-voc2012.html">PASCAL VOC2012</a>,    <a href="https://FairyOnIce.github.io/tag/object-detection-using-rcnn-on-pascal-voc2012-series.html">Object Detection using RCNN on Pascal VOC2012 series</a>,    <a href="https://FairyOnIce.github.io/tag/gps-watch.html">GPS watch</a>,    <a href="https://FairyOnIce.github.io/tag/deep-learning.html">deep learning</a>,    <a href="https://FairyOnIce.github.io/tag/celeba.html">CelebA</a>,    <a href="https://FairyOnIce.github.io/tag/heroku.html">Heroku</a>,    <a href="https://FairyOnIce.github.io/tag/computer-vision.html">Computer Vision</a>,    <a href="https://FairyOnIce.github.io/tag/game.html">Game</a>,    <a href="https://FairyOnIce.github.io/tag/object-detection.html">Object Detection</a>,    <a href="https://FairyOnIce.github.io/tag/interview.html">interview</a>,    <a href="https://FairyOnIce.github.io/tag/tensorflow.html">TensorFlow</a>,    <a href="https://FairyOnIce.github.io/tag/model.html">Model</a>,    <a href="https://FairyOnIce.github.io/tag/natural-language-processing.html">Natural Language Processing</a>,    <a href="https://FairyOnIce.github.io/tag/fourier-transform.html">Fourier Transform</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/notifications/" target="_blank">LinkedIn</a></li>
            <li><a href="https://github.com/FairyOnIce" target="_blank">Github</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="https://getpelican.com/" target="_blank">Pelican</a></li>
            <li><a href="https://python.org/" target="_blank">Python.org</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Yumi -
  <span class="credit">Powered by <a href="https://getpelican.com">Pelican</a></span>
</p></footer>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-112020731-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'https://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-112020731-1');
    ga('send', 'pageview');
</script>
	<script type="text/javascript">
	  var disqus_shortname = 'yumis-blog';
	  (function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	   })();
	</script>
  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
</body>
</html>